import torch
from ultralytics import YOLO
import multiprocessing
import os

def main():
    # --- 1. DonanÄ±m ve HÄ±zlandÄ±rma AyarlarÄ± ---
    if torch.cuda.is_available():
        print(f"ğŸš€ EÄŸitim NVIDIA GPU Ã¼zerinde baÅŸlayacak: {torch.cuda.get_device_name(0)}")
        device = '0'
        workers = 8   # BDD100K bÃ¼yÃ¼k olduÄŸu iÃ§in veri yÃ¼kleme hÄ±zÄ± Ã¶nemli (Linux'ta artÄ±rÄ±labilir)
        batch_size = 16 # VRAM'ine gÃ¶re burayÄ± artÄ±r/azalt.
    elif torch.backends.mps.is_available():
        print("ğŸ EÄŸitim Apple Silicon (Metal) Ã¼zerinde baÅŸlayacak.")
        device = 'mps'
        workers = 4
        batch_size = 16 
    else:
        print("âš ï¸ GPU bulunamadÄ±! CPU kullanÄ±lÄ±yor (Ã‡ok yavaÅŸ olacak).")
        device = 'cpu'
        workers = 0
        batch_size = 4

    # Windows iÃ§in Safe Mode KontrolÃ¼
    if os.name == 'nt': 
        print("ğŸ”§ Windows algÄ±landÄ±. Workers sayÄ±sÄ± gÃ¼venli moda (4) Ã§ekiliyor.")
        # Workers=0 Ã§ok yavaÅŸtÄ±r. Windows'ta genelde 4 Ã§alÄ±ÅŸÄ±r, hata verirse 0 yaparsÄ±n.
        workers = 4 

    # --- 2. Model YÃ¼kleme ---
    # RPi 5 iÃ§in 'nano' (n) idealdir. Biraz daha baÅŸarÄ±m istersen 'small' (s) deneyebilirsin ama FPS dÃ¼ÅŸer.
    model = YOLO('yolo11n.pt') 

    # --- 3. EÄŸitim BaÅŸlatma ---
    print(f"ğŸ¯ EÄŸitim BaÅŸlÄ±yor... Batch Size: {batch_size}, Workers: {workers}")
    
    model.train(
        data='bdd100k/data.yaml',    # AÅŸaÄŸÄ±da vereceÄŸim YAML dosyasÄ±nÄ±n adÄ±
        epochs=100,             # BDD100K iÃ§in 100 iyidir, veri Ã§oksa 50 bile yetebilir.
        imgsz=640,
        batch=batch_size,       # Senin hesapladÄ±ÄŸÄ±n dinamik batch size'Ä± buraya baÄŸladÄ±m!
        device=device,
        workers=workers,
        project='adas_training_nano',
        name='bdd100k_v11_nano', # Ä°simlendirmeyi veri setine uygun yaptÄ±m
        cache=True,            # DÄ°KKAT: BDD100K 100 bin fotoÄŸraftÄ±r. RAM'in 64GB+ deÄŸilse bunu False yap, yoksa RAM taÅŸar!
        amp=True,               
        exist_ok=True,
        patience=20,            # Veri seti zorlu olduÄŸu iÃ§in sabrÄ± biraz artÄ±rdÄ±m (10 -> 20)
        optimizer="AdamW",
        plots=True,
    )

    # --- 4. RPi 5 iÃ§in Export ---
    print("ğŸ“¦ Model NCNN formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor (RPi iÃ§in)...")
    # NCNN, Raspberry Pi Ã¼zerindeki Vulkan GPU hÄ±zlandÄ±rmasÄ± iÃ§in en iyisidir.
    model.export(format='ncnn', imgsz=640)

if __name__ == '__main__':
    multiprocessing.freeze_support()
    main()
